{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "t2t_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbHaLsYbOIdY"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwhNO5KHS9CX",
        "outputId": "d8f9ddfb-373d-4082-f550-ee19470fa832"
      },
      "source": [
        "!pip install -q -U tensorflow-gpu==1.15.2\n",
        "!pip install -q -U tensorflow-datasets==3.2.1\n",
        "!pip install -q -U tensor2tensor\n",
        " \n",
        "import tensorflow as tf\n",
        "import os\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        " \n",
        "project_dir = \"/gdrive/MyDrive/transformer-chatbot/\"\n",
        "MODEL_DIR = project_dir + \"saved_model/t2t_chatbot/\"\n",
        "DATASET_DIR = project_dir + \"conversational-dataset/\"\n",
        " \n",
        "!mkdir -p $DATASET_DIR\n",
        "!mkdir -p $MODEL_DIR\n",
        " \n",
        "tf.get_logger().propagate = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 411.0MB 42kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 56.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 53.1MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 33.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 33.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.5MB 47.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 48.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 53.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 50.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 59.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 58.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 61.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 58.5MB/s \n",
            "\u001b[?25h  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-VmGzKXDgbR"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRN4fw3bDfig"
      },
      "source": [
        "MAX_SAMPLES = 40000000\n",
        "DATA_DIR = MODEL_DIR + 'data'\n",
        "TMP_DIR = MODEL_DIR + 'tmp'\n",
        "TRAIN_DIR = MODEL_DIR + 'train'\n",
        "PROBLEM = 'chat_bot'\n",
        " \n",
        "USE_TPU = False\n",
        "MODEL = \"evolved_transformer\"\n",
        "HPARAMS = \"evolved_transformer_base\"\n",
        "NUM_ENCODER_LAYERS = 1\n",
        "NUM_DECODER_LAYERS = 12\n",
        "BATCH_SIZE = 4096\n",
        "MAX_LENGTH = 40\n",
        "VOCAB_SIZE = 2**13\n",
        " \n",
        "CONVERSATION_TURNS = 3\n",
        "\n",
        "TRAIN_STEPS = 300000 # Total number of train steps for all Epochs\n",
        "EVAL_STEPS = 100 # Number of steps to perform for each evaluation\n",
        "SAVE_CHECKPOINTS_STEPS = 5000\n",
        "KEEP_CHECKPOINT_MAX = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfValt_ONGRM"
      },
      "source": [
        "## Problem definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EjbmT4pVUZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17754c0b-926e-40fe-935f-ae870d3c358a"
      },
      "source": [
        "from tensor2tensor.data_generators import problem\n",
        "from tensor2tensor.data_generators import text_problems\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.data_generators import text_encoder\n",
        "from collections import deque\n",
        "import re\n",
        "\n",
        "PATH_TO_DATASET = DATASET_DIR + 'it'\n",
        "PATH_TO_PREPROCESSED = DATASET_DIR + \"preprocessed.txt\"\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"[^a-zA-Z0-9?.!,àèìòùáéíóú']+\", \" \", sentence)\n",
        "    sentence = sentence.replace(\" ' \", \" \")\n",
        "    sentence = sentence.strip()\n",
        "    return sentence\n",
        "\n",
        "if not os.path.isfile(PATH_TO_DATASET):\n",
        "    path_to_zip = tf.keras.utils.get_file(\n",
        "        DATASET_DIR + \"it.gz\",\n",
        "        origin='http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.it.gz')\n",
        "\n",
        "    !gzip -dk $path_to_zip\n",
        "\n",
        "if not os.path.isfile(PATH_TO_PREPROCESSED):\n",
        "    dataset_file = open(PATH_TO_DATASET, 'r')\n",
        "    preprocessed_file = open(PATH_TO_PREPROCESSED, 'w')\n",
        "    for i in range(MAX_SAMPLES):\n",
        "        line = dataset_file.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = preprocess_sentence(line)\n",
        "        if line:\n",
        "            preprocessed_file.write(line + '\\n')\n",
        "    preprocessed_file.close()\n",
        "    dataset_file.close()\n",
        "else:\n",
        "    print(\"preprocessed dataset already exists\")\n",
        "        \n",
        "\n",
        "@registry.register_problem\n",
        "class ChatBot(text_problems.Text2TextProblem):\n",
        "    @property\n",
        "    def approx_vocab_size(self):\n",
        "        return VOCAB_SIZE\n",
        "    \n",
        "    @property\n",
        "    def is_generate_per_split(self):\n",
        "        return False\n",
        " \n",
        "    @property\n",
        "    def dataset_splits(self):\n",
        "        return [{\n",
        "            \"split\": problem.DatasetSplit.TRAIN,\n",
        "            \"shards\": 9,\n",
        "        }, {\n",
        "            \"split\": problem.DatasetSplit.EVAL,\n",
        "            \"shards\": 1,\n",
        "        }]\n",
        "\n",
        "    SENTENCE_SEPARATOR = \"<SEP>\"\n",
        "    SENTENCE_SEPARATOR_ID = 2\n",
        "\n",
        "    @property\n",
        "    def additional_reserved_tokens(self):\n",
        "        return [self.SENTENCE_SEPARATOR]\n",
        " \n",
        "    def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
        "        conversation = deque()\n",
        "        with open(PATH_TO_PREPROCESSED, 'r') as file:\n",
        "            conversation.append(file.readline().rstrip())\n",
        "            line = file.readline()\n",
        "            while line:\n",
        "                conversation.append(line.rstrip())\n",
        "                if len(conversation) > CONVERSATION_TURNS + 1:\n",
        "                    conversation.popleft()\n",
        "                yield {\n",
        "                    'inputs': list(conversation)[:-1], \n",
        "                    'targets': conversation[-1]\n",
        "                }\n",
        "                line = file.readline()\n",
        "\n",
        "    def generate_text_for_vocab(self, data_dir, tmp_dir):\n",
        "        with open(PATH_TO_PREPROCESSED, 'r') as file:\n",
        "            line = file.readline()\n",
        "            while line:\n",
        "                yield line.strip()\n",
        "                line = file.readline()\n",
        "\n",
        "    def generate_encoded_samples(self, data_dir, tmp_dir, dataset_split):\n",
        "\n",
        "        generator = self.generate_samples(data_dir, tmp_dir, dataset_split)\n",
        "        encoder = self.get_or_create_vocab(data_dir, tmp_dir)\n",
        "\n",
        "        def generate_encoded(generator, encoder):\n",
        "            count = 0\n",
        "            num_subwords_dataset = 0\n",
        "            for sample in generator:\n",
        "                encoded_inputs = []\n",
        "                for conversation_turn in sample[\"inputs\"]:\n",
        "                    encoded_inputs.extend(encoder.encode(conversation_turn))\n",
        "                    encoded_inputs.append(self.SENTENCE_SEPARATOR_ID)\n",
        "                encoded_inputs.pop()\n",
        "                encoded_inputs.append(text_encoder.EOS_ID)\n",
        "                if len(encoded_inputs) > MAX_LENGTH:\n",
        "                    encoded_inputs = encoded_inputs[-MAX_LENGTH:]\n",
        "                sample[\"inputs\"] = encoded_inputs\n",
        "                sample[\"targets\"] = encoder.encode(sample[\"targets\"])\n",
        "                sample[\"targets\"].append(text_encoder.EOS_ID)\n",
        "                # print some examples\n",
        "                if count > 100 and count < 110:\n",
        "                    print(\"_______INPUT_______\")\n",
        "                    print(encoder.decode(sample[\"inputs\"]))\n",
        "                    print(\"_______TARGET_______\")\n",
        "                    print(encoder.decode(sample[\"targets\"]))\n",
        "                count += 1\n",
        "                num_subwords_dataset += max(len(sample[\"inputs\"]), len(sample[\"targets\"]))\n",
        "                yield sample\n",
        "            print(f\"Num samples: {count}\")\n",
        "            print(f\"Tot number of subwords in the dataset: {num_subwords_dataset}\")\n",
        "\n",
        "        return generate_encoded(generator, encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessed dataset already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIyjiL7UNTWb"
      },
      "source": [
        "## Generate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVGPrUn1ebUj",
        "outputId": "5dcffa1f-f64d-42ee-8717-7f40cf0ffdca"
      },
      "source": [
        "from tensor2tensor import problems\n",
        "\n",
        "t2t_problem = problems.problem(PROBLEM)\n",
        "t2t_problem.generate_data(DATA_DIR, TMP_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found vocab file: /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/vocab.chat_bot.8192.subwords\n",
            "INFO:tensorflow:Skipping generator because outputs files exists at ['/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00000-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00001-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00002-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00003-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00004-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00005-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00006-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00007-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-train-00008-of-00009', '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-unshuffled-dev-00000-of-00001']\n",
            "INFO:tensorflow:Skipping shuffle because output files exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlOFYJKQNWd8"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhdhrKFpZmaK",
        "outputId": "624f5327-3f7a-4084-b0ce-c58b35fb1745"
      },
      "source": [
        "from tensor2tensor.utils.trainer_lib import create_run_config, create_experiment\n",
        "from tensor2tensor.utils.trainer_lib import create_hparams\n",
        "from tensor2tensor.utils import registry, hparam, learning_rate\n",
        "from tensor2tensor import models, problems\n",
        "import json\n",
        "\n",
        "# Init Hparams object from T2T Problem\n",
        "hparams = create_hparams(HPARAMS)\n",
        "\n",
        "# Make Changes to Hparams\n",
        "hparams.num_encoder_layers = NUM_ENCODER_LAYERS\n",
        "hparams.num_decoder_layers = NUM_DECODER_LAYERS\n",
        "hparams.batch_size = BATCH_SIZE\n",
        "hparams.max_length = MAX_LENGTH\n",
        "hparams.optimizer = 'Adafactor'\n",
        "hparams.learning_rate_constant = 0.01\n",
        "hparams.learning_rate_warmup_steps = 10000\n",
        "hparams.learning_rate_schedule = \"constant*rsqrt_normalized_decay\"\n",
        "# disable dropout because one epoch training\n",
        "hparams.dropout = 0.0\n",
        "hparams.layer_prepostprocess_dropout = 0.0\n",
        "hparams.attention_dropout = 0.0\n",
        "hparams.relu_dropout = 0.0\n",
        "hparams.symbol_dropout = 0.0\n",
        "\n",
        "\n",
        "hparams_json = hparams.to_json()\n",
        "print(str(hparams_json))\n",
        "\n",
        "# Save hparams \n",
        "with open(MODEL_DIR + 'hparams.json', 'w') as json_file:\n",
        "    json_file.write(hparams_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "{\"batch_size\": 4096, \"batch_shuffle_size\": 512, \"use_fixed_batch_size\": false, \"num_hidden_layers\": 6, \"kernel_height\": 3, \"kernel_width\": 1, \"hidden_size\": 512, \"compress_steps\": 0, \"dropout\": 0.0, \"clip_grad_norm\": 0.0, \"grad_noise_scale\": 0.0, \"summarize_grads\": false, \"mlperf_mode\": false, \"summarize_vars\": false, \"initializer\": \"uniform_unit_scaling\", \"initializer_gain\": 1.0, \"label_smoothing\": 0.1, \"optimizer\": \"Adafactor\", \"optimizer_adam_epsilon\": 1e-09, \"optimizer_adam_beta1\": 0.9, \"optimizer_adam_beta2\": 0.997, \"optimizer_momentum_momentum\": 0.9, \"optimizer_momentum_nesterov\": false, \"optimizer_adafactor_beta1\": 0.0, \"optimizer_adafactor_beta2\": 0.999, \"optimizer_adafactor_factored\": true, \"optimizer_adafactor_decay_type\": \"pow\", \"optimizer_adafactor_memory_exponent\": 0.8, \"optimizer_adafactor_clipping_threshold\": 1.0, \"optimizer_adafactor_multiply_by_parameter_scale\": true, \"optimizer_multistep_accumulate_steps\": 0, \"mixed_precision_optimizer_loss_scaler\": \"exponential\", \"mixed_precision_optimizer_init_loss_scale\": 32768, \"optimizer_zero_grads\": false, \"weight_decay\": 0.0, \"weight_noise\": 0.0, \"learning_rate_schedule\": \"constant*rsqrt_normalized_decay\", \"learning_rate_constant\": 0.01, \"learning_rate_decay_scheme\": \"noam\", \"learning_rate_decay_steps\": 5000, \"learning_rate_decay_staircase\": false, \"learning_rate_minimum\": null, \"learning_rate_decay_rate\": 1.0, \"learning_rate_warmup_steps\": 10000, \"learning_rate_cosine_cycle_steps\": 250000, \"learning_rate\": 0.2, \"sampling_method\": \"argmax\", \"sampling_temp\": 1.0, \"sampling_keep_top_k\": -1, \"factored_logits\": false, \"multiply_embedding_mode\": \"sqrt_depth\", \"moe_hidden_sizes\": \"2048\", \"moe_num_experts\": 16, \"moe_k\": 2, \"moe_loss_coef\": 0.001, \"layer_preprocess_sequence\": \"n\", \"layer_postprocess_sequence\": \"da\", \"layer_prepostprocess_dropout\": 0.0, \"layer_prepostprocess_dropout_broadcast_dims\": \"\", \"symbol_dropout\": 0.0, \"norm_type\": \"layer\", \"norm_epsilon\": 1e-06, \"vocab_divisor\": 1, \"min_length\": 0, \"max_length\": 40, \"pack_dataset\": false, \"use_custom_ops\": true, \"split_targets_chunk_length\": 0, \"split_targets_max_chunks\": 100, \"split_targets_strided_training\": false, \"min_length_bucket\": 8, \"length_bucket_step\": 1.1, \"eval_drop_long_sequences\": false, \"eval_run_autoregressive\": false, \"shared_embedding_and_softmax_weights\": true, \"shared_embedding\": false, \"symbol_modality_num_shards\": 16, \"bottom\": {}, \"loss\": {}, \"name\": {}, \"top\": {}, \"weights_fn\": {}, \"max_input_seq_length\": 0, \"max_target_seq_length\": 0, \"split_to_length\": 0, \"video_num_input_frames\": 1, \"video_num_target_frames\": 1, \"prepend_mode\": \"none\", \"scheduled_sampling_prob\": 0.0, \"scheduled_sampling_method\": \"parallel\", \"scheduled_sampling_warmup_steps\": 50000, \"scheduled_sampling_gold_mixin_prob\": 0.5, \"scheduled_sampling_num_passes\": 1, \"scheduled_sampling_warmup_schedule\": \"exp\", \"daisy_chain_variables\": true, \"force_full_predict\": false, \"no_data_parallelism\": false, \"activation_dtype\": \"float32\", \"weight_dtype\": \"float32\", \"pretrained_model_dir\": \"\", \"multiproblem_schedule_threshold\": 0.5, \"multiproblem_per_task_threshold\": \"\", \"multiproblem_schedule_max_examples\": 10000000.0, \"multiproblem_mixing_schedule\": \"constant\", \"multiproblem_reweight_label_loss\": false, \"multiproblem_label_weight\": 0.5, \"max_relative_position\": 0, \"heads_share_relative_embedding\": false, \"add_relative_to_values\": false, \"tpu_enable_host_call\": false, \"pad_batch\": false, \"multiproblem_target_eval_only\": false, \"multiproblem_vocab_size\": -1, \"multiproblem_max_input_length\": -1, \"multiproblem_max_target_length\": -1, \"multiproblem_fixed_train_length\": -1, \"warm_start_from_second\": \"\", \"area_value_mode\": \"none\", \"area_key_mode\": \"none\", \"num_area_layers\": 0, \"max_area_width\": 1, \"max_area_height\": 1, \"memory_height\": 1, \"gpu_automatic_mixed_precision\": false, \"filter_size\": 2048, \"num_encoder_layers\": 1, \"num_decoder_layers\": 12, \"num_heads\": 8, \"attention_key_channels\": 0, \"attention_value_channels\": 0, \"ffn_layer\": \"dense_relu_dense\", \"parameter_attention_key_channels\": 0, \"parameter_attention_value_channels\": 0, \"attention_dropout\": 0.0, \"attention_dropout_broadcast_dims\": \"\", \"relu_dropout\": 0.0, \"relu_dropout_broadcast_dims\": \"\", \"pos\": \"timing\", \"position_features\": \"\", \"nbr_decoder_problems\": 1, \"proximity_bias\": false, \"causal_decoder_self_attention\": true, \"use_pad_remover\": true, \"self_attention_type\": \"dot_product\", \"conv_first_kernel\": 3, \"attention_variables_3d\": false, \"use_target_space_embedding\": true, \"moe_overhead_train\": 1.0, \"moe_overhead_eval\": 2.0, \"overload_eval_metric_name\": \"\", \"unidirectional_encoder\": false, \"hard_attention_k\": 0, \"gumbel_noise_weight\": 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS142dbdfugS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876d40e4-68c8-4080-9183-1a126df76353"
      },
      "source": [
        "RUN_CONFIG = create_run_config(\n",
        "      model_dir=TRAIN_DIR,\n",
        "      model_name=MODEL,\n",
        "      save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS,\n",
        "      keep_checkpoint_max = KEEP_CHECKPOINT_MAX\n",
        ")\n",
        "\n",
        "tensorflow_exp_fn = create_experiment(\n",
        "        run_config=RUN_CONFIG,\n",
        "        hparams=hparams,\n",
        "        model_name=MODEL,\n",
        "        problem_name=PROBLEM,\n",
        "        data_dir=DATA_DIR, \n",
        "        train_steps=TRAIN_STEPS, \n",
        "        eval_steps=EVAL_STEPS, \n",
        "        use_tpu=USE_TPU,\n",
        "        schedule=\"continuous_train_and_eval\",\n",
        "        eval_throttle_seconds=300,\n",
        "        use_xla=True # For acceleration\n",
        "    ) \n",
        "\n",
        "tensorflow_exp_fn.continuous_train_and_eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:248: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "INFO:tensorflow:sync=False\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:caching_devices: None\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f365b204a90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_save_checkpoints_steps': 5000, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train', '_session_creation_timeout_secs': 7200, 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f365b204b00>}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f365b31db70>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading data files from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-train*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 9\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/problem.py:689: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:276: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:38: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/grouping.py:194: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:234: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
            "INFO:tensorflow:num_trainable_top_decoder_layers is negative so training all weights.\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "WARNING:tensorflow:Entity <function framework at 0x7f3669724400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n",
            "WARNING: Entity <function framework at 0x7f3669724400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_23791_512.bottom\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_23791_512.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:95: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Entity <function attention_bias_to_padding at 0x7f3667f5d598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n",
            "WARNING: Entity <function attention_bias_to_padding at 0x7f3667f5d598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n",
            "WARNING:tensorflow:Entity <function layers at 0x7f36683dc158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7f365811f3c8>\n",
            "WARNING: Entity <function layers at 0x7f36683dc158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7f365811f3c8>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/evolved_transformer.py:475: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/evolved_transformer.py:612: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_23791_512.top\n",
            "INFO:tensorflow:Base learning rate: 0.010000\n",
            "INFO:tensorflow:Trainable Variables Total size: 107905536\n",
            "INFO:tensorflow:Non-trainable variables Total size: 5\n",
            "INFO:tensorflow:Using optimizer Adafactor\n",
            "WARNING:tensorflow:optimizer names now keyed by snake_case names. Please update `registry.optimizer` callsite (likely due to a `HParams.optimizer` value)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-25000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 25000 into /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt.\n",
            "INFO:tensorflow:loss = 3.0916715, step = 25000\n",
            "INFO:tensorflow:global_step/sec: 0.4413\n",
            "INFO:tensorflow:loss = 3.1383226, step = 25100 (226.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.796537\n",
            "INFO:tensorflow:loss = 3.37129, step = 25200 (125.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.815107\n",
            "INFO:tensorflow:loss = 3.0815017, step = 25300 (122.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830059\n",
            "INFO:tensorflow:loss = 3.1787102, step = 25400 (120.473 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.822064\n",
            "INFO:tensorflow:loss = 3.248667, step = 25500 (121.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818642\n",
            "INFO:tensorflow:loss = 3.3156943, step = 25600 (122.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831977\n",
            "INFO:tensorflow:loss = 3.20462, step = 25700 (120.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818521\n",
            "INFO:tensorflow:loss = 2.7892978, step = 25800 (122.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.81656\n",
            "INFO:tensorflow:loss = 3.2182007, step = 25900 (122.463 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.817666\n",
            "INFO:tensorflow:loss = 3.3544602, step = 26000 (122.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825599\n",
            "INFO:tensorflow:loss = 3.2244847, step = 26100 (121.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831702\n",
            "INFO:tensorflow:loss = 3.2462742, step = 26200 (120.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826909\n",
            "INFO:tensorflow:loss = 3.1767182, step = 26300 (120.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827363\n",
            "INFO:tensorflow:loss = 3.2507935, step = 26400 (120.867 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.823451\n",
            "INFO:tensorflow:loss = 3.2863343, step = 26500 (121.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819205\n",
            "INFO:tensorflow:loss = 3.2197614, step = 26600 (122.072 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.809868\n",
            "INFO:tensorflow:loss = 3.229043, step = 26700 (123.475 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.82292\n",
            "INFO:tensorflow:loss = 2.9820807, step = 26800 (121.517 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826886\n",
            "INFO:tensorflow:loss = 3.0057034, step = 26900 (120.937 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828253\n",
            "INFO:tensorflow:loss = 3.1630297, step = 27000 (120.733 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827986\n",
            "INFO:tensorflow:loss = 3.0225527, step = 27100 (120.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.821333\n",
            "INFO:tensorflow:loss = 2.9320762, step = 27200 (121.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.82818\n",
            "INFO:tensorflow:loss = 3.0742366, step = 27300 (120.741 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.823883\n",
            "INFO:tensorflow:loss = 3.138146, step = 27400 (121.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833229\n",
            "INFO:tensorflow:loss = 2.82664, step = 27500 (120.010 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831298\n",
            "INFO:tensorflow:loss = 3.0997643, step = 27600 (120.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828769\n",
            "INFO:tensorflow:loss = 2.9956052, step = 27700 (120.660 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836643\n",
            "INFO:tensorflow:loss = 3.1894836, step = 27800 (119.521 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828336\n",
            "INFO:tensorflow:loss = 3.162155, step = 27900 (120.725 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834872\n",
            "INFO:tensorflow:loss = 3.254412, step = 28000 (119.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826551\n",
            "INFO:tensorflow:loss = 3.1094332, step = 28100 (120.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.835795\n",
            "INFO:tensorflow:loss = 3.2710183, step = 28200 (119.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829377\n",
            "INFO:tensorflow:loss = 3.1194441, step = 28300 (120.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834481\n",
            "INFO:tensorflow:loss = 3.0241404, step = 28400 (119.831 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.846592\n",
            "INFO:tensorflow:loss = 3.1474404, step = 28500 (118.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833302\n",
            "INFO:tensorflow:loss = 3.0792842, step = 28600 (120.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831058\n",
            "INFO:tensorflow:loss = 3.2713575, step = 28700 (120.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828814\n",
            "INFO:tensorflow:loss = 3.2382112, step = 28800 (120.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833855\n",
            "INFO:tensorflow:loss = 3.0711973, step = 28900 (119.922 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825054\n",
            "INFO:tensorflow:loss = 3.1759694, step = 29000 (121.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836692\n",
            "INFO:tensorflow:loss = 3.2472055, step = 29100 (119.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834942\n",
            "INFO:tensorflow:loss = 3.118197, step = 29200 (119.768 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.83542\n",
            "INFO:tensorflow:loss = 2.8459363, step = 29300 (119.696 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833858\n",
            "INFO:tensorflow:loss = 3.0189407, step = 29400 (119.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.816944\n",
            "INFO:tensorflow:loss = 3.026268, step = 29500 (122.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834733\n",
            "INFO:tensorflow:loss = 3.2135231, step = 29600 (119.803 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831366\n",
            "INFO:tensorflow:loss = 3.0228643, step = 29700 (120.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824407\n",
            "INFO:tensorflow:loss = 3.21004, step = 29800 (121.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.838359\n",
            "INFO:tensorflow:loss = 3.2644274, step = 29900 (119.279 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 30000 into /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Reading data files from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:num_trainable_top_decoder_layers is negative so training all weights.\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_23791_512.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_23791_512.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_23791_512.top\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-21T10:11:59Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-30000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2021-02-21-10:13:15\n",
            "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 3.68368, metrics-chat_bot/targets/accuracy = 0.36668494, metrics-chat_bot/targets/accuracy_per_sequence = 0.0073072705, metrics-chat_bot/targets/accuracy_top5 = 0.5605142, metrics-chat_bot/targets/approx_bleu_score = 0.023688028, metrics-chat_bot/targets/neg_log_perplexity = -3.664881, metrics-chat_bot/targets/rouge_2_fscore = 0.1062103, metrics-chat_bot/targets/rouge_L_fscore = 0.12949023\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-30000\n",
            "INFO:tensorflow:global_step/sec: 0.456076\n",
            "INFO:tensorflow:loss = 3.1501024, step = 30000 (219.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819973\n",
            "INFO:tensorflow:loss = 3.2931192, step = 30100 (121.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829655\n",
            "INFO:tensorflow:loss = 3.049683, step = 30200 (120.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836197\n",
            "INFO:tensorflow:loss = 2.7837071, step = 30300 (119.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.839045\n",
            "INFO:tensorflow:loss = 2.9778883, step = 30400 (119.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829407\n",
            "INFO:tensorflow:loss = 3.2926164, step = 30500 (120.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829133\n",
            "INFO:tensorflow:loss = 3.2598474, step = 30600 (120.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.837376\n",
            "INFO:tensorflow:loss = 3.0546434, step = 30700 (119.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832072\n",
            "INFO:tensorflow:loss = 3.2430227, step = 30800 (120.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.835752\n",
            "INFO:tensorflow:loss = 3.3594918, step = 30900 (119.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.839106\n",
            "INFO:tensorflow:loss = 3.1201808, step = 31000 (119.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832757\n",
            "INFO:tensorflow:loss = 2.866926, step = 31100 (120.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836049\n",
            "INFO:tensorflow:loss = 2.9864347, step = 31200 (119.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830291\n",
            "INFO:tensorflow:loss = 3.114668, step = 31300 (120.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832322\n",
            "INFO:tensorflow:loss = 3.086869, step = 31400 (120.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827964\n",
            "INFO:tensorflow:loss = 3.243398, step = 31500 (120.780 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836908\n",
            "INFO:tensorflow:loss = 3.0902064, step = 31600 (119.487 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831256\n",
            "INFO:tensorflow:loss = 3.0093393, step = 31700 (120.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834727\n",
            "INFO:tensorflow:loss = 3.2040975, step = 31800 (119.796 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.837127\n",
            "INFO:tensorflow:loss = 3.32855, step = 31900 (119.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834228\n",
            "INFO:tensorflow:loss = 3.2052405, step = 32000 (119.871 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.839411\n",
            "INFO:tensorflow:loss = 3.0408666, step = 32100 (119.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831784\n",
            "INFO:tensorflow:loss = 3.1448538, step = 32200 (120.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.839998\n",
            "INFO:tensorflow:loss = 3.3963864, step = 32300 (119.046 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.83607\n",
            "INFO:tensorflow:loss = 3.1893063, step = 32400 (119.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831487\n",
            "INFO:tensorflow:loss = 3.085082, step = 32500 (120.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824089\n",
            "INFO:tensorflow:loss = 3.1456535, step = 32600 (121.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830962\n",
            "INFO:tensorflow:loss = 3.1733012, step = 32700 (120.338 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831559\n",
            "INFO:tensorflow:loss = 3.159662, step = 32800 (120.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829393\n",
            "INFO:tensorflow:loss = 2.9509084, step = 32900 (120.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825892\n",
            "INFO:tensorflow:loss = 2.9974792, step = 33000 (121.076 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.841803\n",
            "INFO:tensorflow:loss = 3.2745512, step = 33100 (118.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.83484\n",
            "INFO:tensorflow:loss = 3.0782022, step = 33200 (119.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834824\n",
            "INFO:tensorflow:loss = 3.2266233, step = 33300 (119.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831281\n",
            "INFO:tensorflow:loss = 3.120182, step = 33400 (120.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.82882\n",
            "INFO:tensorflow:loss = 3.0899515, step = 33500 (120.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825975\n",
            "INFO:tensorflow:loss = 2.9148362, step = 33600 (121.073 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836836\n",
            "INFO:tensorflow:loss = 3.194151, step = 33700 (119.497 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836087\n",
            "INFO:tensorflow:loss = 3.1592734, step = 33800 (119.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818172\n",
            "INFO:tensorflow:loss = 3.1449509, step = 33900 (122.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.834948\n",
            "INFO:tensorflow:loss = 3.179839, step = 34000 (119.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832105\n",
            "INFO:tensorflow:loss = 3.185035, step = 34100 (120.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825587\n",
            "INFO:tensorflow:loss = 3.0250516, step = 34200 (121.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831915\n",
            "INFO:tensorflow:loss = 2.9516337, step = 34300 (120.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830288\n",
            "INFO:tensorflow:loss = 3.0685184, step = 34400 (120.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832152\n",
            "INFO:tensorflow:loss = 3.0016432, step = 34500 (120.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830073\n",
            "INFO:tensorflow:loss = 3.07543, step = 34600 (120.472 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828406\n",
            "INFO:tensorflow:loss = 3.2437532, step = 34700 (120.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833794\n",
            "INFO:tensorflow:loss = 3.043383, step = 34800 (119.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825554\n",
            "INFO:tensorflow:loss = 3.091409, step = 34900 (121.131 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 35000 into /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:num_trainable_top_decoder_layers is negative so training all weights.\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_23791_512.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_23791_512.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_23791_512.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-21T11:53:46Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-35000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2021-02-21-11:54:59\n",
            "INFO:tensorflow:Saving dict for global step 35000: global_step = 35000, loss = 3.6564665, metrics-chat_bot/targets/accuracy = 0.37004846, metrics-chat_bot/targets/accuracy_per_sequence = 0.0068688346, metrics-chat_bot/targets/accuracy_top5 = 0.56511694, metrics-chat_bot/targets/approx_bleu_score = 0.024654143, metrics-chat_bot/targets/neg_log_perplexity = -3.6377735, metrics-chat_bot/targets/rouge_2_fscore = 0.11296446, metrics-chat_bot/targets/rouge_L_fscore = 0.13263017\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35000: /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-35000\n",
            "INFO:tensorflow:global_step/sec: 0.463911\n",
            "INFO:tensorflow:loss = 2.6819208, step = 35000 (215.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832302\n",
            "INFO:tensorflow:loss = 2.8350313, step = 35100 (120.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.84084\n",
            "INFO:tensorflow:loss = 3.0819433, step = 35200 (118.924 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836815\n",
            "INFO:tensorflow:loss = 3.308936, step = 35300 (119.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.839909\n",
            "INFO:tensorflow:loss = 3.0734017, step = 35400 (119.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820266\n",
            "INFO:tensorflow:loss = 2.8697896, step = 35500 (121.907 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831867\n",
            "INFO:tensorflow:loss = 2.946486, step = 35600 (120.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832564\n",
            "INFO:tensorflow:loss = 3.2681615, step = 35700 (120.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.843962\n",
            "INFO:tensorflow:loss = 2.9654014, step = 35800 (118.487 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833458\n",
            "INFO:tensorflow:loss = 3.0441165, step = 35900 (119.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.82555\n",
            "INFO:tensorflow:loss = 3.3014643, step = 36000 (121.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.837159\n",
            "INFO:tensorflow:loss = 3.0604517, step = 36100 (119.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825584\n",
            "INFO:tensorflow:loss = 2.6930177, step = 36200 (121.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832525\n",
            "INFO:tensorflow:loss = 3.0336056, step = 36300 (120.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830043\n",
            "INFO:tensorflow:loss = 3.2444408, step = 36400 (120.477 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.839408\n",
            "INFO:tensorflow:loss = 3.1841605, step = 36500 (119.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.840362\n",
            "INFO:tensorflow:loss = 3.2939677, step = 36600 (118.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.830381\n",
            "INFO:tensorflow:loss = 3.0774117, step = 36700 (120.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829919\n",
            "INFO:tensorflow:loss = 3.2627923, step = 36800 (120.489 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.838679\n",
            "INFO:tensorflow:loss = 3.1039052, step = 36900 (119.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827877\n",
            "INFO:tensorflow:loss = 3.270567, step = 37000 (120.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826889\n",
            "INFO:tensorflow:loss = 3.1213937, step = 37100 (120.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826563\n",
            "INFO:tensorflow:loss = 3.1978033, step = 37200 (120.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831975\n",
            "INFO:tensorflow:loss = 3.2076628, step = 37300 (120.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.838565\n",
            "INFO:tensorflow:loss = 3.1436477, step = 37400 (119.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.837823\n",
            "INFO:tensorflow:loss = 3.379696, step = 37500 (119.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831372\n",
            "INFO:tensorflow:loss = 3.2902458, step = 37600 (120.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832462\n",
            "INFO:tensorflow:loss = 2.881248, step = 37700 (120.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.840546\n",
            "INFO:tensorflow:loss = 3.0749002, step = 37800 (118.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832144\n",
            "INFO:tensorflow:loss = 3.0696666, step = 37900 (120.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833012\n",
            "INFO:tensorflow:loss = 3.0614464, step = 38000 (120.044 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829796\n",
            "INFO:tensorflow:loss = 3.032719, step = 38100 (120.512 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.813819\n",
            "INFO:tensorflow:loss = 2.9934554, step = 38200 (122.879 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.823537\n",
            "INFO:tensorflow:loss = 3.056729, step = 38300 (121.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828826\n",
            "INFO:tensorflow:loss = 3.090417, step = 38400 (120.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819292\n",
            "INFO:tensorflow:loss = 3.1570601, step = 38500 (122.060 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826094\n",
            "INFO:tensorflow:loss = 3.1597078, step = 38600 (121.052 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820337\n",
            "INFO:tensorflow:loss = 2.8836687, step = 38700 (121.897 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826162\n",
            "INFO:tensorflow:loss = 3.0325701, step = 38800 (121.046 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826225\n",
            "INFO:tensorflow:loss = 3.0341809, step = 38900 (121.028 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826833\n",
            "INFO:tensorflow:loss = 2.8281295, step = 39000 (120.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820682\n",
            "INFO:tensorflow:loss = 3.0763085, step = 39100 (121.853 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820947\n",
            "INFO:tensorflow:loss = 2.957634, step = 39200 (121.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.836306\n",
            "INFO:tensorflow:loss = 3.1824305, step = 39300 (119.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819791\n",
            "INFO:tensorflow:loss = 3.2668753, step = 39400 (121.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818001\n",
            "INFO:tensorflow:loss = 3.0169985, step = 39500 (122.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820285\n",
            "INFO:tensorflow:loss = 3.039311, step = 39600 (121.912 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.823195\n",
            "INFO:tensorflow:loss = 2.8356936, step = 39700 (121.480 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.833613\n",
            "INFO:tensorflow:loss = 3.1578982, step = 39800 (119.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831443\n",
            "INFO:tensorflow:loss = 3.0494463, step = 39900 (120.276 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 40000 into /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:num_trainable_top_decoder_layers is negative so training all weights.\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_23791_512.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_23791_512.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_23791_512.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-21T13:35:47Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-40000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2021-02-21-13:37:01\n",
            "INFO:tensorflow:Saving dict for global step 40000: global_step = 40000, loss = 3.6341486, metrics-chat_bot/targets/accuracy = 0.37127924, metrics-chat_bot/targets/accuracy_per_sequence = 0.008987943, metrics-chat_bot/targets/accuracy_top5 = 0.56762064, metrics-chat_bot/targets/approx_bleu_score = 0.024977395, metrics-chat_bot/targets/neg_log_perplexity = -3.6159017, metrics-chat_bot/targets/rouge_2_fscore = 0.10714171, metrics-chat_bot/targets/rouge_L_fscore = 0.1323945\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-40000\n",
            "INFO:tensorflow:global_step/sec: 0.459554\n",
            "INFO:tensorflow:loss = 3.1193461, step = 40000 (217.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.821165\n",
            "INFO:tensorflow:loss = 2.9997725, step = 40100 (121.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826472\n",
            "INFO:tensorflow:loss = 3.0594225, step = 40200 (120.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824946\n",
            "INFO:tensorflow:loss = 2.7457135, step = 40300 (121.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.822862\n",
            "INFO:tensorflow:loss = 3.2805665, step = 40400 (121.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.821141\n",
            "INFO:tensorflow:loss = 3.0867703, step = 40500 (121.780 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819608\n",
            "INFO:tensorflow:loss = 2.4358046, step = 40600 (122.006 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829143\n",
            "INFO:tensorflow:loss = 3.206783, step = 40700 (120.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.838001\n",
            "INFO:tensorflow:loss = 3.3236208, step = 40800 (119.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819523\n",
            "INFO:tensorflow:loss = 2.9698908, step = 40900 (122.024 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826858\n",
            "INFO:tensorflow:loss = 3.0698771, step = 41000 (120.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826696\n",
            "INFO:tensorflow:loss = 3.221026, step = 41100 (120.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.814983\n",
            "INFO:tensorflow:loss = 3.045533, step = 41200 (122.703 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.831846\n",
            "INFO:tensorflow:loss = 3.244251, step = 41300 (120.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.821233\n",
            "INFO:tensorflow:loss = 3.038423, step = 41400 (121.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818422\n",
            "INFO:tensorflow:loss = 3.1960313, step = 41500 (122.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825096\n",
            "INFO:tensorflow:loss = 2.6686428, step = 41600 (121.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.816958\n",
            "INFO:tensorflow:loss = 3.387455, step = 41700 (122.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.832583\n",
            "INFO:tensorflow:loss = 3.2247274, step = 41800 (120.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828973\n",
            "INFO:tensorflow:loss = 3.198314, step = 41900 (120.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824593\n",
            "INFO:tensorflow:loss = 2.9989285, step = 42000 (121.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818989\n",
            "INFO:tensorflow:loss = 2.8783927, step = 42100 (122.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.825065\n",
            "INFO:tensorflow:loss = 3.2058666, step = 42200 (121.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826891\n",
            "INFO:tensorflow:loss = 3.1718922, step = 42300 (120.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.826484\n",
            "INFO:tensorflow:loss = 2.971736, step = 42400 (120.990 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819818\n",
            "INFO:tensorflow:loss = 2.9887483, step = 42500 (121.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818281\n",
            "INFO:tensorflow:loss = 3.1272187, step = 42600 (122.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.821115\n",
            "INFO:tensorflow:loss = 3.015492, step = 42700 (121.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829851\n",
            "INFO:tensorflow:loss = 3.0518827, step = 42800 (120.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.81463\n",
            "INFO:tensorflow:loss = 3.0425043, step = 42900 (122.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.823256\n",
            "INFO:tensorflow:loss = 3.1903257, step = 43000 (121.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824621\n",
            "INFO:tensorflow:loss = 3.0625196, step = 43100 (121.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820603\n",
            "INFO:tensorflow:loss = 3.171165, step = 43200 (121.860 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.822066\n",
            "INFO:tensorflow:loss = 3.078241, step = 43300 (121.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824126\n",
            "INFO:tensorflow:loss = 2.904262, step = 43400 (121.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.815987\n",
            "INFO:tensorflow:loss = 3.1908834, step = 43500 (122.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819199\n",
            "INFO:tensorflow:loss = 3.133661, step = 43600 (122.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827377\n",
            "INFO:tensorflow:loss = 3.209063, step = 43700 (120.868 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.822047\n",
            "INFO:tensorflow:loss = 3.2276402, step = 43800 (121.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.822947\n",
            "INFO:tensorflow:loss = 2.9807682, step = 43900 (121.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.823605\n",
            "INFO:tensorflow:loss = 2.7474465, step = 44000 (121.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.824951\n",
            "INFO:tensorflow:loss = 3.0150917, step = 44100 (121.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.818657\n",
            "INFO:tensorflow:loss = 3.0586796, step = 44200 (122.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829654\n",
            "INFO:tensorflow:loss = 3.043204, step = 44300 (120.533 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.813195\n",
            "INFO:tensorflow:loss = 2.908319, step = 44400 (122.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829632\n",
            "INFO:tensorflow:loss = 3.335188, step = 44500 (120.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827371\n",
            "INFO:tensorflow:loss = 3.1695433, step = 44600 (120.862 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.827006\n",
            "INFO:tensorflow:loss = 2.820419, step = 44700 (120.923 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.83197\n",
            "INFO:tensorflow:loss = 3.3334901, step = 44800 (120.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820483\n",
            "INFO:tensorflow:loss = 3.1409154, step = 44900 (121.876 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 45000 into /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt.\n",
            "INFO:tensorflow:Reading data files from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/data/chat_bot-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:num_trainable_top_decoder_layers is negative so training all weights.\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_23791_512.bottom\n",
            "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_23791_512.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_23791_512.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-02-21T15:18:35Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-45000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2021-02-21-15:19:49\n",
            "INFO:tensorflow:Saving dict for global step 45000: global_step = 45000, loss = 3.5972135, metrics-chat_bot/targets/accuracy = 0.374314, metrics-chat_bot/targets/accuracy_per_sequence = 0.008841798, metrics-chat_bot/targets/accuracy_top5 = 0.57170075, metrics-chat_bot/targets/approx_bleu_score = 0.025959728, metrics-chat_bot/targets/neg_log_perplexity = -3.5797994, metrics-chat_bot/targets/rouge_2_fscore = 0.111209124, metrics-chat_bot/targets/rouge_L_fscore = 0.1342094\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 45000: /gdrive/MyDrive/transformer-chatbot/saved_model/t2t_chatbot/train/model.ckpt-45000\n",
            "INFO:tensorflow:global_step/sec: 0.458021\n",
            "INFO:tensorflow:loss = 3.0535638, step = 45000 (218.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.829513\n",
            "INFO:tensorflow:loss = 3.0625205, step = 45100 (120.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.819169\n",
            "INFO:tensorflow:loss = 2.9681423, step = 45200 (122.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.820673\n",
            "INFO:tensorflow:loss = 2.9963083, step = 45300 (121.846 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.828111\n",
            "INFO:tensorflow:loss = 3.0098011, step = 45400 (120.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.816898\n",
            "INFO:tensorflow:loss = 2.9305494, step = 45500 (122.416 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGOC25N4dWdM"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jQ0uvnw-wff"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.utils import hparams_lib\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.data_generators import text_problems\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# sampling parameters\n",
        "SAMPLING_TEMPERATURE = 0.88\n",
        "NUM_SAMPLES = 5\n",
        "MAX_LCS_RATIO = 0.8\n",
        "\n",
        "tfe = tf.contrib.eager\n",
        "tfe.enable_eager_execution()\n",
        "Modes = tf.estimator.ModeKeys\n",
        " \n",
        "chat_bot_problem = problems.problem(\"chat_bot\")\n",
        "ckpt_path = tf.train.latest_checkpoint(TRAIN_DIR)\n",
        "encoders = chat_bot_problem.feature_encoders(DATA_DIR)\n",
        "hparams = hparams_lib.create_hparams_from_json(MODEL_DIR + 'hparams.json')\n",
        "hparams.data_dir = DATA_DIR\n",
        "hparams_lib.add_problem_hparams(hparams, \"chat_bot\")\n",
        "hparams.sampling_method = \"random\"\n",
        "hparams.sampling_temp = SAMPLING_TEMPERATURE\n",
        " \n",
        "chatbot_model = registry.model(MODEL)(hparams, Modes.PREDICT)\n",
        " \n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.replace(\"'\", \"' \")\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z0-9?.!,àèìòùáéíóú']+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence\n",
        "\n",
        "def postprocess_sentence(sentence):\n",
        "    # remove space before punctuation\n",
        "    sentence = sentence.rstrip(\" .\")\n",
        "    return re.sub(r\"\\s+(\\W)\", r\"\\1\", sentence)\n",
        "\n",
        "def encode(conversation, output_str=None):\n",
        "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "    encoded_inputs = []\n",
        "    for conversation_turn in conversation:\n",
        "        encoded_inputs += encoders[\"inputs\"].encode(conversation_turn) + [2]\n",
        "    encoded_inputs.pop()\n",
        "    encoded_inputs += [1]\n",
        "    if len(encoded_inputs) > hparams.max_length:\n",
        "        encoded_inputs = encoded_inputs[-hparams.max_length:]\n",
        "    batch_inputs = tf.reshape(encoded_inputs, [1, -1, 1])  # Make it 3D.\n",
        "    return {\"inputs\": batch_inputs}\n",
        "\n",
        "def decode(integers):\n",
        "    \"\"\"List of ints to str\"\"\"\n",
        "    integers = list(np.squeeze(integers))\n",
        "    if 1 in integers:\n",
        "        integers = integers[:integers.index(1)]\n",
        "    decoded = encoders[\"inputs\"].decode(integers)\n",
        "    return postprocess_sentence(decoded)\n",
        "\n",
        "def lcs_ratio(context, predicted): \n",
        "    m = len(context) \n",
        "    n = len(predicted) \n",
        "    L = [[None]*(n + 1) for i in range(m + 1)] \n",
        "    for i in range(m + 1): \n",
        "        for j in range(n + 1): \n",
        "            if i == 0 or j == 0 : \n",
        "                L[i][j] = 0\n",
        "            elif context[i-1] == predicted[j-1]: \n",
        "                L[i][j] = L[i-1][j-1]+1\n",
        "            else: \n",
        "                L[i][j] = max(L[i-1][j], L[i][j-1]) \n",
        "    return L[m][n] / n\n",
        "\n",
        "def predict(conversation):\n",
        "    preprocessed = [preprocess_sentence(x) for x in conversation]\n",
        "    encoded_inputs = encode(preprocessed)\n",
        "    with tfe.restore_variables_on_create(ckpt_path):\n",
        "        while True:\n",
        "            output_candidates = [chatbot_model.infer(encoded_inputs) for _ in range(NUM_SAMPLES)]\n",
        "            output_candidates.sort(key = lambda x: -float(x[\"scores\"]))\n",
        "\n",
        "            for x in output_candidates:\n",
        "                print(str(float(x[\"scores\"])) + \"\\t\" + decode(x[\"outputs\"]))\n",
        "\n",
        "            for candidate in output_candidates:\n",
        "                decoded = decode(candidate[\"outputs\"])\n",
        "                if lcs_ratio(\" \".join(preprocessed), decoded) < MAX_LCS_RATIO:\n",
        "                    return decoded\n",
        " \n",
        " \n",
        "conversation = []\n",
        "while True:\n",
        "    sentence = input(\"Input: \")\n",
        "    conversation.append(sentence)\n",
        "    while len(conversation) > CONVERSATION_TURNS: \n",
        "        conversation.pop(0)\n",
        "    response = predict(conversation)\n",
        "    conversation.append(response)\n",
        "    print(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJcdhi0s7cx9"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKtXU6xt65Xj"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $TRAIN_DIR"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}